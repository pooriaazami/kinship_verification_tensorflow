{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa37d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "from utils.DataLoader import load_data\n",
    "from models.SiameseNet import SiameseModel, build_network\n",
    "from models.Attention import CBAM\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd44e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(dataset, test_fold, batch_size=128):\n",
    "    if dataset == 'KI':\n",
    "        train_dataset = load_data(f'data\\\\KinFaceWITrainFolds{test_fold}.tfrecords', batch_size=batch_size)\n",
    "        validation_dataset = load_data(f'data\\\\KinFaceWITestFolds{test_fold}.tfrecords', batch_size=batch_size)\n",
    "    elif dataset == 'KII':\n",
    "        train_dataset = load_data(f'data\\\\KinFaceWIITrainFolds{test_fold}.tfrecords', batch_size=batch_size)\n",
    "        validation_dataset = load_data(f'data\\\\KinFaceWIITestFolds{test_fold}.tfrecords', batch_size=batch_size)\n",
    "        \n",
    "    \n",
    "    return train_dataset, validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d3b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskModel(keras.models.Model):\n",
    "    def __init__(self, mask_model, alpha=.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mask_model = mask_model\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def call(self, x):\n",
    "        mask = self.mask_model(x)\n",
    "        mask = tf.argmax(mask, -1)\n",
    "        mask = tf.expand_dims(mask, 3)\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "        \n",
    "        x = self.alpha * mask + (1 - self.alpha) * x\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd23ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_network(use_cbam, train_vgg, embedding_size):\n",
    "    input_layer = layers.Input((64, 64, 3))\n",
    "    vgg = VGGFace(model='vgg16', include_top=False, input_shape=(64, 64, 3))\n",
    "    \n",
    "    if use_cbam:\n",
    "        cbam = CBAM(3)(input_layer)\n",
    "        x = vgg(cbam)\n",
    "    else:\n",
    "        x = vgg(input_layer)\n",
    "        \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    output_layer = layers.Dense(embedding_size)(x)\n",
    "\n",
    "    network = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    if not train_vgg:\n",
    "        for layer in vgg.layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "    return network\n",
    "\n",
    "def add_prior_attention_to_model(base_model):\n",
    "    mask_generator = keras.models.load_model('model.h5')\n",
    "    mask_model = MaskModel(mask_generator, .2)\n",
    "    \n",
    "    input_layer = layers.Input((64, 64, 3))\n",
    "    x = mask_model(input_layer)\n",
    "    x = base_model(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=input_layer, outputs=x)\n",
    "    \n",
    "    for layer in mask_generator.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_final_model(use_prior=False, use_cbam=True, train_vgg=False, embedding_size=1024):\n",
    "    network = build_siamese_network(use_cbam, train_vgg, embedding_size)\n",
    "    \n",
    "    if use_prior:\n",
    "        network = add_prior_attention_to_model(network)\n",
    "        \n",
    "    siamese_network = build_network(network)\n",
    "    model = SiameseModel(siamese_network)\n",
    "    \n",
    "    return model, network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69dab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataset, validation_dataset):\n",
    "    model.compile(optimizer=keras.optimizers.Adam(0.001))\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20),\n",
    "        tf.keras.callbacks.CSVLogger('.\\\\log.csv', separator=\",\", append=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_accuracy',\n",
    "                factor=0.1,\n",
    "                patience=5,\n",
    "                verbose=1,\n",
    "                min_lr=1e-7\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(train_dataset, epochs=1, validation_data=validation_dataset, callbacks=callbacks)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a85b7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 93.98 --> Prior, CBAM, batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86608d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_config(use_prior, use_cbam, train_vgg, embedding_size, dataset, fold, batch_size=16):\n",
    "    train_dataset, validation_dataset = load_datasets(dataset, fold, batch_size)\n",
    "    model, network = build_final_model(use_prior, use_cbam, train_vgg, embedding_size)\n",
    "    history = train_model(model, train_dataset, validation_dataset)\n",
    "    \n",
    "    del network, model, train_dataset, validation_dataset\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb43422a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'use_prior': True, 'use_cbam': True, 'train_vgg': True, 'dataset': 'KII', 'test_fold': '1'}\n",
      "44925/44925 [==============================] - 5199s 116ms/step - loss: 0.4997 - accuracy: 0.9966 - ap_mean: 0.0017 - ap_std: 147817120.0000 - an_mean: 38246668.0000 - an_std: 147817120.0000 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': True, 'use_cbam': True, 'train_vgg': True, 'dataset': 'KII', 'test_fold': '2'}\n",
      "79900/79900 [==============================] - 9002s 113ms/step - loss: 6095.1963 - accuracy: 0.9891 - ap_mean: 33705.8711 - ap_std: 471295.5000 - an_mean: 405156.9062 - an_std: 471295.5000 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': True, 'use_cbam': True, 'train_vgg': True, 'dataset': 'KII', 'test_fold': '3'}\n",
      "79900/79900 [==============================] - 9031s 113ms/step - loss: 123.7998 - accuracy: 0.9332 - ap_mean: 408.7800 - ap_std: 1703.6545 - an_mean: 1335.9128 - an_std: 1703.6545 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': True, 'use_cbam': True, 'train_vgg': True, 'dataset': 'KII', 'test_fold': '4'}\n",
      "79900/79900 [==============================] - 9090s 114ms/step - loss: 0.9808 - accuracy: 0.9784 - ap_mean: 1.9534 - ap_std: 4863.2988 - an_mean: 1342.7438 - an_std: 4863.2988 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': False, 'use_cbam': True, 'train_vgg': True, 'dataset': 'KI', 'test_fold': '1'}\n",
      "22738/22738 [==============================] - 1822s 80ms/step - loss: 0.5000 - accuracy: 1.0000 - ap_mean: 0.0000e+00 - ap_std: 0.0000e+00 - an_mean: 0.0000e+00 - an_std: 0.0000e+00 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': False, 'use_cbam': True, 'train_vgg': True, 'dataset': 'KI', 'test_fold': '2'}\n",
      "22738/22738 [==============================] - 1825s 80ms/step - loss: 68.4484 - accuracy: 0.9947 - ap_mean: 384.7570 - ap_std: 1965.7455 - an_mean: 1883.8597 - an_std: 1965.7455 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': False, 'use_cbam': True, 'train_vgg': True, 'dataset': 'KI', 'test_fold': '3'}\n",
      "22738/22738 [==============================] - 1816s 80ms/step - loss: 52.9113 - accuracy: 0.9980 - ap_mean: 461.4443 - ap_std: 18718.8242 - an_mean: 11852.3496 - an_std: 18718.8242 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': False, 'use_cbam': True, 'train_vgg': True, 'dataset': 'KI', 'test_fold': '4'}\n",
      "22419/22419 [==============================] - 1800s 80ms/step - loss: 10498.1641 - accuracy: 0.9472 - ap_mean: 19657.9395 - ap_std: 34992.5547 - an_mean: 27314.5918 - an_std: 34992.5547 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': False, 'use_cbam': True, 'train_vgg': True, 'dataset': 'KII', 'test_fold': '1'}\n",
      "44925/44925 [==============================] - 3602s 80ms/step - loss: 441.9191 - accuracy: 0.9928 - ap_mean: 1011.3997 - ap_std: 2817.7229 - an_mean: 2357.3037 - an_std: 2817.7229 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': False, 'use_cbam': True, 'train_vgg': True, 'dataset': 'KII', 'test_fold': '2'}\n",
      "79900/79900 [==============================] - 6404s 80ms/step - loss: 0.5713 - accuracy: 0.9956 - ap_mean: 0.9815 - ap_std: 135.8645 - an_mean: 42.5619 - an_std: 135.8645 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': False, 'use_cbam': True, 'train_vgg': True, 'dataset': 'KII', 'test_fold': '3'}\n",
      "79900/79900 [==============================] - 6368s 80ms/step - loss: 1.2051 - accuracy: 0.9860 - ap_mean: 3.4286 - ap_std: 1533.5955 - an_mean: 467.3252 - an_std: 1533.5955 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': False, 'use_cbam': True, 'train_vgg': True, 'dataset': 'KII', 'test_fold': '4'}\n",
      "79900/79900 [==============================] - 6338s 79ms/step - loss: 29.1771 - accuracy: 0.9974 - ap_mean: 235.9675 - ap_std: 4622.8936 - an_mean: 4369.1235 - an_std: 4622.8936 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': True, 'use_cbam': False, 'train_vgg': True, 'dataset': 'KI', 'test_fold': '1'}\n",
      "22738/22738 [==============================] - 2458s 108ms/step - loss: 458328.6250 - accuracy: 0.9235 - ap_mean: 2200405.5000 - ap_std: 18496982.0000 - an_mean: 10046846.0000 - an_std: 18496982.0000 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': True, 'use_cbam': False, 'train_vgg': True, 'dataset': 'KI', 'test_fold': '2'}\n",
      "22738/22738 [==============================] - 2456s 108ms/step - loss: 22.9493 - accuracy: 0.9944 - ap_mean: 159.7100 - ap_std: 2899.2817 - an_mean: 2567.6780 - an_std: 2899.2817 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': True, 'use_cbam': False, 'train_vgg': True, 'dataset': 'KI', 'test_fold': '3'}\n",
      "22738/22738 [==============================] - 2470s 109ms/step - loss: 20.7245 - accuracy: 0.9986 - ap_mean: 200.2737 - ap_std: 3407.9841 - an_mean: 3033.8140 - an_std: 3407.9841 - val_loss: 0.5000 - val_accuracy: 1.0000 - val_ap_mean: 0.0000e+00 - val_ap_std: 0.0000e+00 - val_an_mean: 0.0000e+00 - val_an_std: 0.0000e+00\n",
      "{'use_prior': True, 'use_cbam': False, 'train_vgg': True, 'dataset': 'KI', 'test_fold': '4'}\n",
      "    479/Unknown - 58s 116ms/step - loss: 2088.6367 - accuracy: 0.9757 - ap_mean: 10337.1807 - ap_std: 46843.0938 - an_mean: 50826.9609 - an_std: 46843.0938"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[512,512,3,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model_39/model_38/model_37/vggface_vgg16/conv5_1/Conv2D_1/Conv2DBackpropFilter (defined at D:\\Kinship Verification\\tensorflow_codes\\models\\SiameseNet.py:73) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_4779478]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/model_39/model_38/model_37/vggface_vgg16/conv5_1/Conv2D_1/Conv2DBackpropFilter:\n model_39/model_38/model_37/vggface_vgg16/pool4/MaxPool_1 (defined at D:\\Kinship Verification\\tensorflow_codes\\models\\SiameseNet.py:111)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 109\u001b[0m\n\u001b[0;32m    107\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(config)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m#                     use_prior, use_cbam, train_vgg, embedding_size, dataset, fold, batch_size=16\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m                     history \u001b[38;5;241m=\u001b[39m \u001b[43mlog_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_prior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cbam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_vgg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m                     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m history\n\u001b[0;32m    113\u001b[0m                     logs\u001b[38;5;241m.\u001b[39mappend(config)\n",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m, in \u001b[0;36mlog_config\u001b[1;34m(use_prior, use_cbam, train_vgg, embedding_size, dataset, fold, batch_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m train_dataset, validation_dataset \u001b[38;5;241m=\u001b[39m load_datasets(dataset, fold, batch_size)\n\u001b[0;32m      3\u001b[0m model, network \u001b[38;5;241m=\u001b[39m build_final_model(use_prior, use_cbam, train_vgg, embedding_size)\n\u001b[1;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m network, model, train_dataset, validation_dataset\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_dataset, validation_dataset)\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m0.001\u001b[39m))\n\u001b[0;32m      4\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m),\n\u001b[0;32m      6\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mCSVLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mlog.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     )\n\u001b[0;32m     14\u001b[0m ]\n\u001b[1;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow-env\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow-env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[512,512,3,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model_39/model_38/model_37/vggface_vgg16/conv5_1/Conv2D_1/Conv2DBackpropFilter (defined at D:\\Kinship Verification\\tensorflow_codes\\models\\SiameseNet.py:73) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_4779478]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/model_39/model_38/model_37/vggface_vgg16/conv5_1/Conv2D_1/Conv2DBackpropFilter:\n model_39/model_38/model_37/vggface_vgg16/pool4/MaxPool_1 (defined at D:\\Kinship Verification\\tensorflow_codes\\models\\SiameseNet.py:111)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# batch_sizes = [16]\n",
    "# embedding_sizes = [1024] \n",
    "use_prior_list = [True, False]\n",
    "use_cbam_list = [True, False] \n",
    "train_vgg_list = [False, True]\n",
    "datasets = ['KI', 'KII']\n",
    "folds = ['0', '1', '2', '3', '4']\n",
    "\n",
    "logs = []\n",
    "counter = 0\n",
    "\n",
    "methods = {\n",
    "    (True, True, False, 'KI', '0'),\n",
    "    (True, True, False, 'KI', '1'),\n",
    "    (True, True, False, 'KI', '2'),\n",
    "    (True, True, False, 'KI', '3'),\n",
    "    (True, True, False, 'KI', '4'),\n",
    "    \n",
    "    (True, True, False, 'KII', '0'),\n",
    "    (True, True, False, 'KII', '1'),\n",
    "    (True, True, False, 'KII', '2'),\n",
    "    (True, True, False, 'KII', '3'),\n",
    "    (True, True, False, 'KII', '4'),\n",
    "    \n",
    "    (False, True, False, 'KI', '0'),\n",
    "    (False, True, False, 'KI', '1'),\n",
    "    (False, True, False, 'KI', '2'),\n",
    "    (False, True, False, 'KI', '3'),\n",
    "    (False, True, False, 'KI', '4'),\n",
    "    \n",
    "    (False, True, False, 'KII', '0'),\n",
    "    (False, True, False, 'KII', '1'),\n",
    "    (False, True, False, 'KII', '2'),\n",
    "    (False, True, False, 'KII', '3'),\n",
    "    (False, True, False, 'KII', '4'),\n",
    "    \n",
    "    (True, False, False, 'KI', '0'),\n",
    "    (True, False, False, 'KI', '1'),\n",
    "    (True, False, False, 'KI', '2'),\n",
    "    (True, False, False, 'KI', '3'),\n",
    "    (True, False, False, 'KI', '4'),\n",
    "    \n",
    "    (True, False, False, 'KII', '0'),\n",
    "    (True, False, False, 'KII', '1'),\n",
    "    (True, False, False, 'KII', '2'),\n",
    "    (True, False, False, 'KII', '3'),\n",
    "    (True, False, False, 'KII', '4'),\n",
    "    \n",
    "    (False, False, False, 'KI', '0'),\n",
    "    (False, False, False, 'KI', '1'),\n",
    "    (False, False, False, 'KI', '2'),\n",
    "    (False, False, False, 'KI', '3'),\n",
    "    (False, False, False, 'KI', '4'),\n",
    "    \n",
    "    (False, False, False, 'KII', '0'),\n",
    "    (False, False, False, 'KII', '1'),\n",
    "    (False, False, False, 'KII', '2'),\n",
    "    (False, False, False, 'KII', '3'),\n",
    "    (False, False, False, 'KII', '4'),\n",
    "    \n",
    "    (True, True, True, 'KI', '0'),\n",
    "    (True, True, True, 'KI', '1'),\n",
    "    (True, True, True, 'KI', '2'),\n",
    "    (True, True, True, 'KI', '3'),\n",
    "    (True, True, True, 'KI', '4'),\n",
    "    \n",
    "    (True, True, True, 'KII', '0'),\n",
    "    \n",
    "    (True, False, True, 'KI', '0'),\n",
    "    \n",
    "    \n",
    "    (True, False, True, 'KII', '0'),\n",
    "    \n",
    "    \n",
    "    (False, False, True, 'KI', '0'),\n",
    "    \n",
    "    \n",
    "    (False, False, True, 'KII', '0'),\n",
    "    \n",
    "    \n",
    "    (False, True, True, 'KI', '0'),\n",
    "    \n",
    "    \n",
    "    (False, True, True, 'KII', '0'),\n",
    "    \n",
    "}\n",
    "for train_vgg in train_vgg_list:\n",
    "    for use_cbam in use_cbam_list:\n",
    "        for use_prior in use_prior_list:\n",
    "            for dataset in datasets:\n",
    "                for fold in folds:\n",
    "                    \n",
    "                    config = {\n",
    "                        'use_prior': use_prior,\n",
    "                        'use_cbam': use_cbam,\n",
    "                        'train_vgg': train_vgg,\n",
    "                        'dataset': dataset,\n",
    "                        'test_fold': fold\n",
    "                    }\n",
    "\n",
    "                    method = (use_prior, use_cbam, train_vgg, dataset, fold)\n",
    "                    if method in methods:\n",
    "                        continue\n",
    "                    else:\n",
    "                        methods.add(method)\n",
    "\n",
    "                    print(config)\n",
    "#                     use_prior, use_cbam, train_vgg, embedding_size, dataset, fold, batch_size=16\n",
    "                    history = log_config(use_prior, use_cbam, train_vgg, 1024, dataset, fold, batch_size=16)\n",
    "                    \n",
    "                    \n",
    "                    config['history'] = history\n",
    "                    logs.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728acd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02751af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90703097",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_log = []\n",
    "\n",
    "for item in logs:\n",
    "    file_log.append({\n",
    "        'use_prior': item['use_prior'],\n",
    "        'use_cbam': item['use_cbam'],\n",
    "        'train_vgg': item['train_vgg'],\n",
    "        'embedding_size': item['embedding_size'],\n",
    "        'dataset': item['dataset'],\n",
    "        'batch_size': item['batch_size'],\n",
    "        'logs': item['history'].history\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca3e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85aa4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "byte_array = pickle.dumps(file_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ablation_study_final.pkl', 'wb') as file:\n",
    "    file.write(byte_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b90c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {'use_prior': True, 'use_cbam': True, 'train_vgg': True, 'embedding_size': 1024, 'dataset': 'KI', 'batch_size': 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7360153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = log_config(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in file_log:\n",
    "#     print(f'prior: {item[\"use_prior\"]}, use cbam:{item[\"use_cbam\"]}, train_vgg: {item[\"train_vgg\"]}, embedding_size:{item[\"embedding_size\"]}, dataset: {item[\"dataset\"]}')\n",
    "#     print(item['logs']['val_accuracy'])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logs[0]['history'].history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bbc6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(6, 3, figsize=(15, 12))\n",
    "# fig.tight_layout(pad=2.0)\n",
    "\n",
    "# for i in range(6):\n",
    "#     for j in range(3):\n",
    "#         idx = i * 3 + j\n",
    "#         item = file_log[idx]\n",
    "#         accuracy = item['logs']['accuracy']\n",
    "#         val_accuracy = item['logs']['val_accuracy']\n",
    "        \n",
    "#         axs[i, j].plot(accuracy, color='blue', label='accuracy')\n",
    "#         axs[i, j].plot(val_accuracy, color='red', label='val_accuracy')\n",
    "#         axs[i, j].legend()\n",
    "        \n",
    "#         label = f'{item[\"use_prior\"]}, {item[\"use_cbam\"]}, {item[\"train_vgg\"]}, {item[\"dataset\"]}, {item[\"embedding_size\"]}, {val_accuracy[-1]:.2f}'\n",
    "        \n",
    "#         axs[i, j].set_title(label)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab551b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_generator = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2feab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebab2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
